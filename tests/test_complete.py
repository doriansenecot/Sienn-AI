#!/usr/bin/env python3
"""
ğŸ§ª Script de Test Complet - ModÃ¨le Fine-tunÃ©
Teste ton modÃ¨le Ã©tape par Ã©tape avec des explications claires
"""
import requests
import json
import sys
import time
from pathlib import Path

API_URL = "http://localhost:8000"

def print_header(text):
    """Affiche un en-tÃªte stylisÃ©"""
    print(f"\n{'='*80}")
    print(f"  {text}")
    print(f"{'='*80}\n")

def print_step(step_num, text):
    """Affiche une Ã©tape"""
    print(f"\n{'â”€'*80}")
    print(f"ğŸ“ Ã‰tape {step_num}: {text}")
    print(f"{'â”€'*80}")

def check_api_status():
    """VÃ©rifie que l'API est accessible"""
    print_step(1, "VÃ©rification de l'API")
    
    try:
        response = requests.get(f"{API_URL}/health", timeout=5)
        if response.status_code == 200:
            print("âœ… API accessible et opÃ©rationnelle")
            return True
        else:
            print(f"âŒ API rÃ©pond avec le code {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Impossible de joindre l'API: {e}")
        print("\nğŸ’¡ Assure-toi que Docker Compose est lancÃ©:")
        print("   cd Sienn-AI && docker compose up -d")
        return False

def upload_test_dataset():
    """Upload le dataset de test"""
    print_step(2, "Upload du dataset de test")
    
    test_file = Path("test_data/test_chat.csv")
    
    if not test_file.exists():
        print(f"âŒ Fichier de test introuvable: {test_file}")
        return None
    
    print(f"ğŸ“‚ Upload de {test_file}...")
    
    try:
        with open(test_file, 'rb') as f:
            files = {'file': ('test_chat.csv', f, 'text/csv')}
            response = requests.post(
                f"{API_URL}/api/upload-dataset",
                files=files,
                timeout=30
            )
        
        if response.status_code == 200:
            data = response.json()
            dataset_id = data.get('dataset_id')
            print(f"âœ… Dataset uploadÃ© avec succÃ¨s!")
            print(f"   ğŸ†” Dataset ID: {dataset_id}")
            return dataset_id
        else:
            print(f"âŒ Erreur upload: {response.status_code}")
            print(response.text)
            return None
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        return None

def start_training(dataset_id):
    """DÃ©marre le training"""
    print_step(3, "DÃ©marrage du training")
    
    payload = {
        "dataset_id": dataset_id,
        "model_name": "gpt2",
        "learning_rate": 0.0002,
        "num_epochs": 3,
        "batch_size": 2,
        "max_length": 128
    }
    
    print("âš™ï¸  Configuration:")
    for key, value in payload.items():
        if key != 'dataset_id':
            print(f"   â€¢ {key}: {value}")
    
    try:
        response = requests.post(
            f"{API_URL}/api/start-finetuning",
            json=payload,
            timeout=30
        )
        
        if response.status_code == 200:
            data = response.json()
            job_id = data.get('job_id')
            print(f"\nâœ… Training dÃ©marrÃ©!")
            print(f"   ğŸ†” Job ID: {job_id}")
            return job_id
        else:
            print(f"âŒ Erreur dÃ©marrage: {response.status_code}")
            print(response.text)
            return None
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        return None

def monitor_training(job_id):
    """Surveille le training"""
    print_step(4, "Surveillance du training")
    print("â³ Attente de la fin du training...")
    print("   (Cela peut prendre plusieurs minutes)\n")
    
    last_progress = -1
    dots = 0
    
    while True:
        try:
            response = requests.get(
                f"{API_URL}/api/training-status/{job_id}",
                timeout=10
            )
            
            if response.status_code == 200:
                data = response.json()
                status = data.get('status')
                progress = data.get('progress', 0)
                message = data.get('message', '')
                
                # Afficher progression si changement
                if progress != last_progress:
                    print(f"\rğŸ”„ Status: {status.upper():<12} | Progress: {progress:>3}% | {message}", end='', flush=True)
                    last_progress = progress
                    dots = 0
                else:
                    # Animation de points
                    dots = (dots + 1) % 4
                    print(f"\rğŸ”„ Status: {status.upper():<12} | Progress: {progress:>3}% {'.' * dots}   ", end='', flush=True)
                
                # Check statut final
                if status == "completed":
                    print("\n\nâœ… Training terminÃ© avec succÃ¨s!")
                    
                    # Afficher les mÃ©triques si disponibles
                    meta = data.get('meta', {})
                    if meta:
                        print("\nğŸ“Š MÃ©triques:")
                        if 'final_loss' in meta:
                            print(f"   â€¢ Loss finale: {meta['final_loss']:.4f}")
                        if 'training_time' in meta:
                            print(f"   â€¢ Temps d'entraÃ®nement: {meta['training_time']}")
                        if 'model_path' in meta:
                            print(f"   â€¢ ModÃ¨le sauvegardÃ©: {meta['model_path']}")
                    
                    return True
                    
                elif status == "failed":
                    print(f"\n\nâŒ Training Ã©chouÃ©!")
                    print(f"   Erreur: {message}")
                    return False
                
            else:
                print(f"\nâŒ Erreur status: {response.status_code}")
                return False
                
        except Exception as e:
            print(f"\nâŒ Erreur monitoring: {e}")
            return False
        
        time.sleep(3)  # Check toutes les 3 secondes

def test_inference(job_id):
    """Teste l'infÃ©rence du modÃ¨le"""
    print_step(5, "Test d'infÃ©rence")
    
    test_prompts = [
        "Qu'est-ce que l'intelligence artificielle?",
        "Comment fonctionne le machine learning?",
        "Explique-moi les rÃ©seaux de neurones",
    ]
    
    print(f"ğŸ¯ Test avec {len(test_prompts)} prompts:\n")
    
    for i, prompt in enumerate(test_prompts, 1):
        print(f"\n{'â”€'*80}")
        print(f"Test #{i}")
        print(f"{'â”€'*80}")
        print(f"ğŸ“ Prompt: {prompt}\n")
        
        payload = {
            "job_id": job_id,
            "prompt": prompt,
            "max_new_tokens": 100,
            "temperature": 0.7
        }
        
        try:
            print("â³ GÃ©nÃ©ration en cours...")
            response = requests.post(
                f"{API_URL}/api/test-model",
                json=payload,
                timeout=60
            )
            
            if response.status_code == 200:
                data = response.json()
                generated_text = data.get('generated_text', '')
                generation_time = data.get('generation_time', 0)
                
                print(f"\nâœ… RÃ©ponse gÃ©nÃ©rÃ©e en {generation_time:.2f}s:")
                print(f"â”Œ{'â”€'*78}â”")
                
                # Afficher le texte ligne par ligne
                for line in generated_text.split('\n'):
                    if line.strip():
                        # Couper les lignes trop longues
                        while len(line) > 76:
                            print(f"â”‚ {line[:76]} â”‚")
                            line = line[76:]
                        print(f"â”‚ {line:<76} â”‚")
                
                print(f"â””{'â”€'*78}â”˜")
            else:
                print(f"âŒ Erreur infÃ©rence: {response.status_code}")
                print(response.text)
        
        except Exception as e:
            print(f"âŒ Erreur: {e}")
        
        # Pause entre les tests
        if i < len(test_prompts):
            time.sleep(1)
    
    return True

def main():
    """Fonction principale"""
    print_header("ğŸš€ TEST COMPLET DU MODÃˆLE FINE-TUNÃ‰")
    
    print("""
Ce script va:
1. VÃ©rifier que l'API est accessible
2. Uploader un dataset de test
3. DÃ©marrer le training
4. Surveiller la progression
5. Tester l'infÃ©rence avec le modÃ¨le entraÃ®nÃ©

PrÃªt? Appuie sur EntrÃ©e pour commencer...
    """)
    
    input()
    
    # Ã‰tape 1: Check API
    if not check_api_status():
        sys.exit(1)
    
    # Ã‰tape 2: Upload dataset
    dataset_id = upload_test_dataset()
    if not dataset_id:
        print("\nâŒ Impossible de continuer sans dataset")
        sys.exit(1)
    
    # Ã‰tape 3: Start training
    job_id = start_training(dataset_id)
    if not job_id:
        print("\nâŒ Impossible de dÃ©marrer le training")
        sys.exit(1)
    
    # Ã‰tape 4: Monitor training
    if not monitor_training(job_id):
        print("\nâŒ Le training a Ã©chouÃ©")
        sys.exit(1)
    
    # Ã‰tape 5: Test inference
    print("\n" + "="*80)
    print("Appuie sur EntrÃ©e pour tester l'infÃ©rence...")
    input()
    
    test_inference(job_id)
    
    # Fin
    print_header("ğŸ‰ TEST TERMINÃ‰ AVEC SUCCÃˆS!")
    
    print(f"""
âœ… Ton modÃ¨le a Ã©tÃ© fine-tunÃ© et testÃ© avec succÃ¨s!

ğŸ“‹ RÃ©sumÃ©:
   â€¢ Job ID: {job_id}
   â€¢ Dataset ID: {dataset_id}
   â€¢ Status: âœ… Completed

ğŸ¯ Prochaines Ã©tapes:
   1. Teste avec tes propres prompts via http://localhost:8000/docs
   2. Export le modÃ¨le pour Ollama
   3. DÃ©ploie en production

ğŸ’¡ Pour tester manuellement:
   curl -X POST http://localhost:8000/api/test-model \\
     -H "Content-Type: application/json" \\
     -d '{{"job_id": "{job_id}", "prompt": "Ton prompt ici"}}'
    """)

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Test interrompu par l'utilisateur")
        sys.exit(1)
    except Exception as e:
        print(f"\n\nâŒ Erreur inattendue: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
